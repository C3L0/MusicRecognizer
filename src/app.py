import gradio as gr
import uvicorn
from fastapi import FastAPI, UploadFile, File, HTTPException
import torch
import librosa
import numpy as np
import os
from transformers import AutoProcessor, ASTForAudioClassification

# 1. Initialisation de FastAPI
app = FastAPI(title="Sound Recognizer API")

# 2. Chargement du modÃ¨le (Ajout de use_fast=True pour enlever le warning)
model_id = "MIT/ast-finetuned-audioset-10-10-0.4593"
processor = AutoProcessor.from_pretrained(model_id, use_fast=True)
model = ASTForAudioClassification.from_pretrained(model_id)

def process_audio(audio_path):
    """Logique partagÃ©e entre l'API et l'Interface"""
    if audio_path is None: return None
    y, sr = librosa.load(audio_path, sr=16000)
    inputs = processor(y, sampling_rate=sr, return_tensors="pt")
    with torch.no_grad():
        logits = model(**inputs).logits
    
    probs = torch.nn.functional.softmax(logits, dim=-1)[0]
    top5_prob, top5_indices = torch.topk(probs, 5)
    return {model.config.id2label[idx.item()]: float(prob) for prob, idx in zip(top5_prob, top5_indices)}

# --- Ã‰TAPE CRUCIALE : DÃ‰FINIR LES ROUTES AVANT LE MOUNT ---

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/predict")
async def predict_api(file: UploadFile = File(...)):
    if not file.content_type.startswith("audio/"):
        raise HTTPException(status_code=400, detail="Le fichier doit Ãªtre un audio.")
    
    temp_path = f"temp_{file.filename}"
    with open(temp_path, "wb") as f:
        f.write(await file.read())
    
    try:
        # On ne rÃ©cupÃ¨re que le premier rÃ©sultat pour l'API simple
        full_res = process_audio(temp_path)
        best_prediction = list(full_res.keys())[0]
        return {"prediction": best_prediction, "filename": file.filename}
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

# --- CONFIGURATION GRADIO ---

custom_css = "#title { text-align: center; color: #1a73e8; }"

with gr.Blocks(css=custom_css) as demo:
    gr.Markdown("# ðŸŽµ Music & Sound Recognizer", elem_id="title")
    
    with gr.Row():
        with gr.Column():
            audio_input = gr.Audio(
                label="Enregistrez ou dÃ©posez un son", 
                type="filepath",
                # On active explicitement le micro et l'upload de fichier
                sources=["microphone", "upload"],
                waveform_options=gr.WaveformOptions(
                    waveform_color="#2196F3",
                    waveform_progress_color="#BBDEFB",
                )
            )
            submit_btn = gr.Button("ðŸš€ Analyser maintenant", variant="primary")

        with gr.Column():
            label_output = gr.Label(num_top_classes=5, label="PrÃ©dictions")

    submit_btn.click(fn=process_audio, inputs=audio_input, outputs=label_output)
    
    # ANALYSE AUTOMATIQUE : se dÃ©clenche au changement (upload ou fin d'enregistrement)
    audio_input.change(fn=process_audio, inputs=audio_input, outputs=label_output)

# MONTAGE FINAL (Gradio vient s'ajouter Ã  FastAPI sans Ã©craser les routes)
app = gr.mount_gradio_app(app, demo, path="/")

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=7860)